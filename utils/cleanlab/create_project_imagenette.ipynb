{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kili Tutorial: Create a project with the Imagenette dataset\n",
    "\n",
    "In this tutorial, we will create a Kili Image Classification project and import the Imagenette dataset (https://github.com/fastai/imagenette).\n",
    "\n",
    "Additionally:\n",
    "\n",
    "For an overview of Kili, visit https://kili-technology.com. You can also check out the Kili documentation https://cloud.kili-technology.com/docs.\n",
    "\n",
    "The tutorial is divided into three parts:\n",
    "\n",
    "1. Downloading the dataset\n",
    "2. Creating the project and importing the assets\n",
    "3. Importing the labels\n",
    "\n",
    "This next cell connects the notebook to the Kili API. You need to update the credentials `api_key` before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#!pip install kili\n",
    "from kili.client import Kili\n",
    "\n",
    "api_key = os.getenv('KILI_USER_API_KEY')\n",
    "\n",
    "kili = Kili(api_key=api_key)\n",
    "\n",
    "#Path where to extract the dataset\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "Depending on the size of the images wanted, you can uncomment the correspoding url. By default, images are downloaded at their full size.\n",
    "\n",
    "The '320 px' and '160 px' versions have their shortest side resized to that size, with their aspect ratio maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "#Full size images\n",
    "url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\"\n",
    "#320px images\n",
    "#url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\"\n",
    "#160px images\n",
    "#url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\"\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "file.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Kili project and importing the assets\n",
    "\n",
    "First, we create a project with a Classification task and introduce the 10 classes present in the Imagenette dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_interface ={\n",
    "    \"jobs\": {\n",
    "        \"CLASSIFICATION_JOB\": {\n",
    "            \"mlTask\": \"CLASSIFICATION\",\n",
    "            \"content\": {\n",
    "                \"categories\": {\n",
    "                    \"TENCH\": {\"name\": \"Tench\"},\n",
    "                    \"ENGLISH_SPRINGER\": {\"name\": \"English springer\"},\n",
    "                    \"CASETTE_PLAYER\": {\"name\": \"Cassette player\"},\n",
    "                    \"CHAIN_SAW\": {\"name\": \"Chain saw\"},\n",
    "                    \"CHURCH\": {\"name\": \"Church\"},\n",
    "                    \"FRENCH_HORN\": {\"name\": \"French horn\"},\n",
    "                    \"GARBAGE_TRUCK\": {\"name\": \"Garbage truck\"},\n",
    "                    \"GAS_PUMP\": {\"name\": \"Gas pump\"},\n",
    "                    \"GOLF_BALL\": {\"name\": \"Golf ball\"},\n",
    "                    \"PARACHUTE\": {\"name\": \"Parachute\"}},\n",
    "                \"input\": \"radio\"\n",
    "            },\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"instruction\": \"Category\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "project_id = kili.create_project(\n",
    "        title='Imagenette',\n",
    "        description='Classification on 10 classes on the Imagenette dataset',\n",
    "        input_type='IMAGE',\n",
    "        json_interface=json_interface\n",
    ")['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create the list containing information about the assets that we will use to import the assets with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = []\n",
    "path = os.path.join(data_path, 'imagenette2/train')\n",
    "\n",
    "for dir in os.listdir(path):\n",
    "    if dir.startswith('n'):\n",
    "        complete_path = os.path.join(path, dir)\n",
    "        for file in os.listdir(complete_path):\n",
    "            if os.path.isfile(os.path.join(complete_path, file)):\n",
    "                assets.append({\n",
    "                    'externalId': file,\n",
    "                    'content': os.path.join(complete_path, file),\n",
    "                    'metadata': {},\n",
    "                })\n",
    "print(f\"Total assets count: {len(assets)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can import all the assets to the Kili project. We do it in chunks of 10 images, to not overcharge the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "CHUNK_SIZE = 10\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "for asset_chunk in tqdm(list(chunks(assets, CHUNK_SIZE))):\n",
    "    external_id_array = [a.get('externalId') for a in asset_chunk]\n",
    "    content_array = [a.get('content') for a in asset_chunk]\n",
    "    json_metadata_array = [a.get('metadata') for a in asset_chunk]\n",
    "    kili.append_many_to_dataset(project_id=project_id, \n",
    "                                      content_array=content_array,\n",
    "                                      external_id_array=external_id_array, \n",
    "                                      json_metadata_array=json_metadata_array)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the labels\n",
    "\n",
    "Now we will add the corresponding label to each asset. First we read the csv file containing all the labels. The column *noisy_label_0* stands for the original label in ImageNet, and the other ones are label that have *x* percent of noise. For example, for *noisy_label_50*, 50% of labels have their labels changed to a wrong one randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, 'imagenette2/noisy_imagenette.csv'))\n",
    "df_train = df[df['is_valid'] == False]\n",
    "df_train['externalId'] = df.apply(lambda row: row['path'].split('/')[-1], axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we upload the labels to Kili. The parameter *upload_noisy* is set to True by default, meaning we will upload two labels for each asset, the original one as a **Review** label and the one with 50% change of being wrong as a **Default** one. If this parameter is set to False, only the original label will be uploaded as a **Default** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_cat = {\n",
    "  'n01440764': 'TENCH',\n",
    "  'n02102040': 'ENGLISH_SPRINGER',\n",
    "  'n02979186': 'CASETTE_PLAYER',\n",
    "  'n03000684': 'CHAIN_SAW',\n",
    "  'n03028079': 'CHURCH',\n",
    "  'n03394916': 'FRENCH_HORN',\n",
    "  'n03417042': 'GARBAGE_TRUCK',\n",
    "  'n03425413': 'GAS_PUMP',\n",
    "  'n03445777': 'GOLF_BALL',\n",
    "  'n03888257': 'PARACHUTE',\n",
    "}\n",
    "\n",
    "upload_noisy = True\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "  time.sleep(0.2)\n",
    "\n",
    "  asset = kili.assets(project_id=project_id, fields=['id', 'externalId'], external_id_contains=[row['externalId']])[0]\n",
    "  label_name = row['noisy_labels_0']\n",
    "  label_name_noisy = row['noisy_labels_50']\n",
    "  label = {\n",
    "      \"CLASSIFICATION_JOB\": {\n",
    "          \"categories\": [{\"name\": name_to_cat[label_name]}]\n",
    "      }\n",
    "  }\n",
    "  if not upload_noisy:\n",
    "    kili.append_to_labels(\n",
    "        json_response=label,\n",
    "        label_asset_id=asset['id'],\n",
    "        label_type='DEFAULT'\n",
    "    )\n",
    "  else:\n",
    "    label_noisy = {\n",
    "        \"CLASSIFICATION_JOB\": {\n",
    "            \"categories\": [{\"name\": name_to_cat[label_name_noisy]}]\n",
    "        }\n",
    "    }\n",
    "    kili.append_to_labels(\n",
    "        json_response=label,\n",
    "        label_asset_id=asset['id'],\n",
    "        label_type='REVIEW'\n",
    "    )\n",
    "    kili.append_to_labels(\n",
    "        json_response=label_noisy,\n",
    "        label_asset_id=asset['id'],\n",
    "        label_type='DEFAULT'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now delete the *data* folder if you want"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
